{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db3ebdc-e41a-4ccd-83f1-ce4446049faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install scipy numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b99309-c135-4235-993b-35164e4c0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b096dd4-094c-4327-92c9-5615c0f10c72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **scipy.optimize**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca44269-e400-431e-b56f-896509fd85ef",
   "metadata": {},
   "source": [
    "## **minimize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea8f623-d886-4527-a1c8-bc5b8633f325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Optimization terminated successfully.\n",
       "  success: True\n",
       "   status: 0\n",
       "      fun: 0.0\n",
       "        x: [-2.000e+00]\n",
       "      nit: 2\n",
       "      jac: [ 0.000e+00]\n",
       " hess_inv: [[ 5.000e-01]]\n",
       "     nfev: 6\n",
       "     njev: 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-2.00000001888464)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_x = lambda x: x**2 + 4*x + 4\n",
    "first_quess = [0]\n",
    "result = sp.optimize.minimize(f_x, x0=first_quess)\n",
    "display(result)\n",
    "x = result['x'][0]\n",
    "assert f_x(x) == 0\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4098761c-0f13-4c9e-8cd8-a8c41c9f0fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " message: Optimization terminated successfully\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: 0.5\n",
       "       x: [ 5.000e-01  5.000e-01]\n",
       "     nit: 3\n",
       "     jac: [ 1.000e+00  1.000e+00]\n",
       "    nfev: 10\n",
       "    njev: 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_x = lambda x: x[0]**2+x[1]**2\n",
    "x0 = np.array([0, 0])\n",
    "eq_cons = {'type': 'eq',\n",
    "             'fun' : lambda x: np.array([-1 + x[0] + x[1]])\n",
    "            }\n",
    "ineq_cons = {'type': 'ineq',\n",
    "             'fun' : lambda x: np.array([x[0], x[1]])\n",
    "            }\n",
    "result = sp.optimize.minimize(f_x, x0, method='SLSQP', constraints=[eq_cons, ineq_cons])\n",
    "display(result)\n",
    "\n",
    "result['x']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6623087e-8cdd-4486-9fb2-90a6f7a2ed9d",
   "metadata": {},
   "source": [
    "## **Example 1: Solve a system of nonlinear equations**\n",
    "\n",
    "Solve the system of equations:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "  x^2 + y^2 - 4 = 0 \\\\\n",
    "  x - y = 0 \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Use `scipy.optimize.fsolve` to solve the system. \n",
    "How would you approach this problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc62df36-17f4-476f-8f82-3bdb6841cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.41421356, 1.41421356])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_x = lambda x: [ \n",
    "    x[0]**2 + x[1]**2 - 4,\n",
    "    x[0] - x[1]\n",
    "]\n",
    "sp.optimize.fsolve(f_x, [0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a523f4f1-1f8c-4a6c-baca-37550b9fe7c1",
   "metadata": {},
   "source": [
    "## **Example 2: Linear Programming**\n",
    "\n",
    "Minimize the objective function:  \n",
    "$$\n",
    "\\min \\, c^T x\n",
    "$$\n",
    "\n",
    "Subject to the constraints:  \n",
    "$$\n",
    "A \\cdot x \\leq b\n",
    "$$\n",
    "\n",
    "### **Problem Setup**\n",
    "\n",
    "Minimize:  \n",
    "$$\n",
    "\\min \\, 2x_1 + 3x_2 \n",
    "$$\n",
    "\n",
    "Subject to:  \n",
    "$$\n",
    "\\begin{cases}\n",
    "  x_1 + 2x_2 \\leq 20 \\\\\n",
    "  2x_1 + x_2 \\leq 20 \\\\\n",
    "  x_1 \\geq 0 \\\\\n",
    "  x_2 \\geq 0 \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Use `scipy.optimize.linprog` to solve this problem. \n",
    "How would you formulate this problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e14564c-0fe6-40fc-beb5-be31143fb9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       message: Optimization terminated successfully. (HiGHS Status 7: Optimal)\n",
       "       success: True\n",
       "        status: 0\n",
       "           fun: 0.0\n",
       "             x: [ 0.000e+00  0.000e+00]\n",
       "           nit: 0\n",
       "         lower:  residual: [ 0.000e+00  0.000e+00]\n",
       "                marginals: [ 2.000e+00  3.000e+00]\n",
       "         upper:  residual: [       inf        inf]\n",
       "                marginals: [ 0.000e+00  0.000e+00]\n",
       "         eqlin:  residual: []\n",
       "                marginals: []\n",
       "       ineqlin:  residual: [ 2.000e+01  2.000e+01]\n",
       "                marginals: [-0.000e+00 -0.000e+00]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [2,3]\n",
    "A_ub = [ [1, 2], [2, 1] ]\n",
    "b_ub = [ 20, 20 ]\n",
    "\n",
    "sp.optimize.linprog(c, A_ub, b_ub, bounds=[(0, None),(0, None)], method='highs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d903bca-2dc2-43a7-85fe-4a4d0838feb2",
   "metadata": {},
   "source": [
    "## **Example 3: Root-finding**\n",
    "\n",
    "Find the root of the following equation:  \n",
    "$$\n",
    "\\cos(x) - x = 0\n",
    "$$\n",
    "\n",
    "Use `scipy.optimize.root_scalar` to solve this problem.  \n",
    "Which method would you use for this and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc2278d9-335c-4e84-8246-ced428c97d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      converged: True\n",
       "           flag: converged\n",
       " function_calls: 10\n",
       "     iterations: 5\n",
       "           root: 0.7390851332151607\n",
       "         method: newton"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "      converged: True\n",
       "           flag: converged\n",
       " function_calls: 8\n",
       "     iterations: 7\n",
       "           root: 0.7390851332151559\n",
       "         method: brentq"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = sp.optimize.root_scalar(lambda x: np.cos(x)-x, x0 = 0)\n",
    "display(result)\n",
    "\n",
    "sp.optimize.root_scalar(lambda x: np.cos(x)-x, bracket=[0, 1], method='brentq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972e1aed-d477-4bf8-af37-22d934cde9b1",
   "metadata": {},
   "source": [
    "## **Example 4: Global Optimization**\n",
    "\n",
    "Find the global minimum of the following function:  \n",
    "$$\n",
    "f(x) = x^4 - 3x^3 + 2\n",
    "$$\n",
    "\n",
    "over the interval:  \n",
    "$$\n",
    "x \\in [-3, 3]\n",
    "$$\n",
    "\n",
    "Use `scipy.optimize.differential_evolution` to solve this problem.  \n",
    "Why is a global optimizer like `differential_evolution` needed for this problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f993b14-3ab4-4881-8671-bfb8dca73488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             message: Optimization terminated successfully.\n",
       "             success: True\n",
       "                 fun: -6.542968749999989\n",
       "                   x: [ 2.250e+00]\n",
       "                 nit: 6\n",
       "                nfev: 111\n",
       "          population: [[ 2.250e+00]\n",
       "                       [ 2.204e+00]\n",
       "                       ...\n",
       "                       [ 2.284e+00]\n",
       "                       [ 2.241e+00]]\n",
       " population_energies: [-6.543e+00 -6.522e+00 ... -6.531e+00 -6.542e+00]\n",
       "                 jac: [ 0.000e+00]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = [(-3, 3)]\n",
    "\n",
    "sp.optimize.differential_evolution(lambda x: x**4 - 3*x**3 + 2, bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d171f5-9ebb-4e04-868a-a6d4dca1a379",
   "metadata": {},
   "source": [
    "### 1. Local vs. Global Minimum\n",
    "When you try to minimize a function, there are two possibilities:\n",
    "- **Local Minimum**: A point where the function value is lower than its neighboring points, but not necessarily the lowest value in the entire range.\n",
    "- **Global Minimum**: The absolute lowest point of the function across the entire search space.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Why Not Use Local Optimizers (like L-BFGS-B or SLSQP)?\n",
    "Many local optimization methods, like gradient descent, Nelder-Mead, or L-BFGS-B, find a minimum starting from an initial guess.  \n",
    "These methods follow the slope of the function downhill. However, if there are multiple \"valleys\" (local minima), the optimizer might get stuck in one of them instead of finding the deepest valley (global minimum).\n",
    "\n",
    "**Example:**\n",
    "$$\n",
    "f(x) = x^4 - 3x^3 + 2\n",
    "$$\n",
    "This function has multiple local minima. If you start at \\(x = -2\\), you might get stuck in a local minimum near \\(x = -1\\) instead of finding the global minimum.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Why Use Differential Evolution?\n",
    "- **Global Search**: Instead of starting from a single point, differential evolution searches the entire space. It doesn't \"get stuck\" in one place like gradient-based methods.  \n",
    "- **Stochastic Approach**: It uses random mutation and recombination inspired by evolutionary biology, so it explores different regions of the space.  \n",
    "- **No Need for Gradients**: It doesn't rely on derivatives, making it useful for non-smooth, non-convex, or complex functions with multiple minima.  \n",
    "\n",
    "---\n",
    "\n",
    "### 4. Key Takeaways\n",
    "- If the function has **one minimum**, local optimizers like L-BFGS-B are fine.  \n",
    "- If the function has **multiple minima**, global optimizers like **Differential Evolution** are needed.  \n",
    "- Differential Evolution searches the **entire space**, whereas local methods follow the gradient, which might get \"stuck\" in local minima.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527fc521-711b-43a4-9958-e79f12cfa6cc",
   "metadata": {},
   "source": [
    "# **scipy.stats**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e0e54-f903-4426-bbb2-85f8ac6a323c",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html#scipy.stats.ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51dd9d-cd78-4965-b80d-b43b57b0c84d",
   "metadata": {},
   "source": [
    "### **Example 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad49e5-2f2f-4508-9887-52d2c0bd54e4",
   "metadata": {},
   "source": [
    "### What Does the p-value Mean?\n",
    "\n",
    "**Null Hypothesis ($H_0$)**: The average weights of apples from Farm A and Farm B are the same.\n",
    "**Alternative Hypothesis ($H_A$)**: The average weights of apples from Farm A and Farm B are different.\n",
    "\n",
    "If the **p-value** is small (typically less than 0.05), we reject the null hypothesis.\n",
    "\n",
    "Here, , which is much larger than 0.05.\n",
    "This means that there is not enough evidence to say that the weights from Farm A and Farm B are significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ab14651-95a9-407c-b9c7-85d6f132c654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=np.float64(-1.0), pvalue=np.float64(0.34659350708733416), df=np.float64(8.0))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farm_a = [150, 155, 160, 165, 170]\n",
    "farm_b = [155, 160, 165, 170, 175]\n",
    "\n",
    "sp.stats.ttest_ind(farm_a, farm_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8bcd6b-610a-471b-8f22-05e641792e8e",
   "metadata": {},
   "source": [
    "### 🔥 Option 2: Chi-Square Test (Goodness of Fit)\n",
    "#### 📝 **Problem Recap**\n",
    "We have data on the favorite colors of 100 people.  \n",
    "Here are the **observed frequencies**:\n",
    "- **Red**: 20  \n",
    "- **Blue**: 30  \n",
    "- **Green**: 25  \n",
    "- **Yellow**: 25  \n",
    "\n",
    "The **expected frequencies** are based on the assumption that 25% of people prefer each color.  \n",
    "Since there are 100 people, the expected frequency for each color is:  \n",
    "$$\n",
    "\\text{Expected} = \\frac{100}{4} = 25\n",
    "$$\n",
    "So, the expected distribution is:  \n",
    "- **Red**: 25  \n",
    "- **Blue**: 25  \n",
    "- **Green**: 25  \n",
    "- **Yellow**: 25  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔥 1️⃣ **Hypotheses**\n",
    "- **Null hypothesis** ($H_0$): The observed frequencies match the expected proportions.  \n",
    "- **Alternative hypothesis** ($H_A$): The observed frequencies differ from the expected proportions.  \n",
    "\n",
    "If the p-value is less than 0.05, we **reject the null hypothesis**, meaning the observed data does not fit the expected proportions.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔥 2️⃣ **Chi-Square Statistic Formula**\n",
    "The formula for the chi-square statistic is:  \n",
    "$$\n",
    "\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "$$\n",
    "Where:  \n",
    "- $O_i$ = observed frequency for category $i$  \n",
    "- $E_i$ = expected frequency for category $i$  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔥 3️⃣ **Results**\n",
    "After calculating the Chi-Square test, we get:  \n",
    "- **Chi-Square Statistic** $\\chi^2$ = 2.0  \n",
    "- **p-value** = 0.5724  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔥 4️⃣ **Interpretation**\n",
    "1. **Chi-Square Statistic**:  \n",
    "   The chi-square value tells us how far the observed frequencies are from the expected frequencies. A small value (like 2.0) means the observed and expected distributions are close to each other.\n",
    "\n",
    "2. **p-value**:  \n",
    "   The p-value is **0.5724**, which is larger than the standard significance level ($\\alpha = 0.05$).  \n",
    "   Since $p > 0.05$, we **fail to reject the null hypothesis**.  \n",
    "   This means the observed data is **not significantly different** from the expected data.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔥 5️⃣ **Summary**\n",
    "- The observed and expected frequencies for color preferences are close enough that we can't say they are statistically different.  \n",
    "- **Conclusion**: The favorite colors of people in this survey align with the expected distribution.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cff760f8-84a2-4269-a145-00d96ba005be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Null Hypothesis True'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat, pval = sp.stats.chisquare(f_obs=[20,30,25,25], f_exp=[25]*4)\n",
    "f'Null Hypothesis {pval > 0.05}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adab5677-e2ff-46f6-b79c-24bc0cdf576b",
   "metadata": {},
   "source": [
    "### 🔥 Option 7: Confidence Interval for the Mean\n",
    "#### 📝 **Problem Recap**\n",
    "You have a sample of 5 apple weights from a farm:  \n",
    "[150, 155, 160, 165, 170]  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔥 1️⃣ **What is a Confidence Interval?**\n",
    "A confidence interval gives a range of values that likely contains the true population mean.  \n",
    "For a **95% confidence interval**, we are 95% confident that the true population mean lies within this range.\n",
    "\n",
    "The formula for a confidence interval for the mean is:  \n",
    "$$\n",
    "\\text{CI} = \\bar{x} \\pm t^* \\cdot \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "Where:  \n",
    "- $\\bar{x}$ = sample mean  \n",
    "- $t^*$ = critical t-value for 95% confidence and $n-1$ degrees of freedom  \n",
    "- $s$ = sample standard deviation  \n",
    "- $n$ = sample size  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔥 2️⃣ **Calculation**\n",
    "- **Sample data**: [150, 155, 160, 165, 170]  \n",
    "- **Sample mean** ($\\bar{x}$) = 160.0  \n",
    "- **Sample size** ($n$) = 5  \n",
    "- **Sample standard deviation** ($s$) = calculated using ddof=1 (sample standard deviation)  \n",
    "\n",
    "Using `scipy.stats.t.interval`, the **95% confidence interval** is calculated as:  \n",
    "- **Lower bound**: 150.18  \n",
    "- **Upper bound**: 169.82  \n",
    "\n",
    "The resulting confidence interval is:  \n",
    "$$\n",
    "[150.18, 169.82]\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 🔥 3️⃣ **Interpretation**\n",
    "1. **Confidence Interval**:  \n",
    "   We are **95% confident** that the true mean weight of apples from this farm lies between **150.18 grams and 169.82 grams**.  \n",
    "\n",
    "2. **Why is it a range?**  \n",
    "   Since we only have a small sample of 5 apples, the confidence interval accounts for the uncertainty in our estimate of the true mean.  \n",
    "   If we repeated this sampling process many times, 95% of the intervals would contain the true population mean.  \n",
    "\n",
    "---\n",
    "\n",
    "### 🔥 4️⃣ **Summary**\n",
    "- **Sample mean**: 160.0 grams  \n",
    "- **95% Confidence Interval**: [150.18, 169.82]  \n",
    "- We are 95% confident that the true mean weight of apples lies in this range.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d8c21dd-c162-40e5-bde2-40600a3a7735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(160.0),\n",
       " np.float64(150.1837841926122),\n",
       " np.float64(169.8162158073878))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data (apple weights)\n",
    "data = [150, 155, 160, 165, 170]\n",
    "\n",
    "# Calculate sample mean and standard error\n",
    "sample_mean = np.mean(data)\n",
    "sample_std = np.std(data, ddof=1)  # Use ddof=1 for sample standard deviation\n",
    "n = len(data)  # Sample size\n",
    "\n",
    "# Calculate the 95% confidence interval using scipy.stats.t.interval\n",
    "confidence_level = 0.95\n",
    "ci_low, ci_high = sp.stats.t.interval(confidence_level, df=n-1, loc=sample_mean, scale=sample_std / np.sqrt(n))\n",
    "\n",
    "sample_mean, ci_low, ci_high\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3db35a-b9db-48cb-b2f0-128271fd9545",
   "metadata": {},
   "source": [
    "# **scipy.linalg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b987daa-6547-4554-9367-b59d6b61442e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f00d4ab-0b76-43fb-b79b-cbf653972970",
   "metadata": {},
   "source": [
    "# **scipy.signal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70deff8c-af70-474b-a00a-f4f6d6deddfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78eab5ca-e3a6-4443-8b10-40cef1436944",
   "metadata": {},
   "source": [
    "# **scipy.optimize.curve_fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af66ebae-a41c-4646-badb-4ba89530fd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d00eb85-5e82-4bcf-8efc-8adecd16990f",
   "metadata": {},
   "source": [
    "# **scipy.sparse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347974f-fe6e-4b72-94d1-43b7ed524b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6f477b3-5f0d-476c-8ff4-3f5c4526e5f4",
   "metadata": {},
   "source": [
    "# **scipy.spatial.distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffa18dc-1270-4035-b8f4-984b4260cc35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
